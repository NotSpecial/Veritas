---
# Pass this file alongwith path to the input directory.

## Dataset
# Naming the log directories.
suffix: Controlled-GT-Cubic-BBA-LMH
# List of sessions to use for training, validation and testing. 
train: full.json
valid: full.json
test: full.json

# INB parameters: We choose the discrete step value of the inferred capacity (capacity unit in Mbps) and the time for which it 
# should be held constant (transition unit in seconds) using these parameter. Max capacity value for the inferred INB should 
# be larger than the observed throughput in the dataset. The max. capacity, granularity of capacity unit and transition time 
# unit can be as granular as possible within computational limits.
capacity_max: 15.0
capacity_unit: 0.05
transition_unit: 1.0

# General parameters for the model: such as random seed for replication of experiments, device type to run, number 
# of epochs, and running the emission functions using C.
seed: 42
device: cpu
num_epochs: 25
jit: true

# HoEHMM model parameters: This relates to the initial probability, transition probability and the emission probability of 
# the states in the HMM model and the associated learning rates. Most of these are standard parameters set for an HMM model. 
initial: generic
transition: gaussian.asym
emission: v17
initeta: 0
transeta: 0.1
vareta: 0.0001
smooth: 0.05
include_beyond: true
trans_extra: 5

# Domain emission model parameters: One of the special parameters used by Veritas is the Domain-specific emission model (f). 
# Veritas has the flexibility to use custom functions for the emission model of Veritasâ€™s High-order Embedded Hidden Markov 
# Model (HoEHMM). For reference, we have included a few emission functions in [fit.py](fit.py) and [transform.py](transform.py) 
# files in the VeritasML directory. These functions use the fields described in the video_session_file (except download time) 
# and possible capacity values for abduction as inputs and return the estimated throughput. We add uncertainty to the 
# emission model in the form of Gaussian white noise with a learnable variance. In our experiments we use a higher variance 
# for the first few chunks (head) to model TCP slow start effects at the start of the session. These parameters are generally 
# lower than the capacity step size and can be tuned per dataset.
varinit: 0.25
head_by_chunk: 5
head_by_time: 5
varmax_head: 1
varmax_rest: 1

